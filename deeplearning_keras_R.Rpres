<style>

.reveal section img {
  border: 0px;
  box-shadow: 0 0 0 0;
}
.reveal table td {
  padding: 2px;
}

.reveal table {
  
}

.reveal h1 {
  font-size: 2em;
}

.reveal h3 {
  font-size: 1.2em;
}

.reveal figcaption {
  font-size: 0.4em;
}

.smallcode pre code {
  font-size: 0.9em;
}

.reveal .smalltext {
  font-size: 0.75em;
}

.reveal .mediumtext {
  font-size: 0.85em;
}

</style>


Deep learning with Keras - using R
========================================================
author: Sigrid Keydana, Trivadis
date: 2017/09/11
autosize: true
incremental:false
width: 1600
height: 900


About me & my employer
========================================================
class:mediumtext


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

Trivadis
- DACH-based IT consulting and service company, from traditional technologies to big data/machine learning/data science

My background
- from psychology/statistics via software development and database engineering to data science and ML/DL

My passion
- machine learning and deep learning
- data science and (Bayesian) statistics
- explanation/understanding over prediction accuracy

Where to find me
- blog: http://recurrentnull.wordpress.com
- twitter: @zkajdan




Welcome to the world of deep neural networks
========================================================

&nbsp;

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


&nbsp;

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=16, fig.height=8, fig.path='Figs/',
                      echo=FALSE, warning=FALSE, message=FALSE,
                      cache = TRUE)
```

```{r}
library(ggplot2)
library(dplyr)
library(forecast)
library(tidyr)
library(keras)
library(gridExtra)
library(EBImage)
library(readr)
library(stringr)
library(purrr)
library(tokenizers)

bold_text_20 <- element_text(face = "bold", size = 20)
bold_text_16 <- element_text(face = "bold", size = 16)
```

<figure>
    <img src='deep_nn.png' width='60%'/>
    <figcaption>Source: https://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol4/cs11/report.html</figcaption>
</figure>




How can we do deep learning in practice?
========================================================
incremental:true

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

Powerful frameworks:

- TensorFlow (Python)
- PyTorch (Python)
- Keras (Python)
- DL4J (Java)
- ...

But we want to use R!

&nbsp;

Let's just use Keras
========================================================
incremental:true


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

... from R!

How? 

With the <a href="https://keras.rstudio.com/"> R Interface to Keras, developed by RStudio</a>



Getting started with Keras
========================================================


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

Four steps:

0. prepare data
1. define model
2. train model
3. test model





Let's see how this works on our most beloved algorithm...
========================================================
incremental:true


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

... linear regression!

... using our most beloved dataset ...


========================================================
incremental:true


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


<figure>
    <img src='iris.jpg' width='60%'/>
</figure>



========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>
Linear regression with Keras
</h1>


The task
========================================================
class:smallcode

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


&nbsp;

We want to predict Petal.Width from Petal.Length ...

```{r, fig.width=8, fig.height = 4}
lm(Petal.Width ~ Petal.Length, data = iris) %>% summary()
ggplot(iris, aes(x = Petal.Length, y = Petal.Width, color = Species)) + geom_point() + geom_smooth()
```


Step 1: Prepare data
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

Not much to do in this case, just split into x/y and test & training sets:

```{r, echo=TRUE}
x_train <- iris[1:120, "Petal.Length"]
y_train <- iris[1:120, "Petal.Width"]
x_test <- iris[121:150, "Petal.Length"]
y_test <- iris[121:150, "Petal.Width"]
```


Step 2: Define model
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, echo=TRUE}
model <- keras_model_sequential()
model %>%
  layer_dense(units = 8, input_shape = 1) %>% # hidden layer with 8 neurons, 1-dimensional input
  layer_activation_leaky_relu() %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 1) # output layer with linear activation

# model %>% summary() # params: num_hidden weights and biases each to hidden layer, 4 weights and 1 bias to output neuron

model %>% compile(optimizer = "adam", loss = "mean_squared_error")
```

&nbsp;

<table style="margin-left: 200px;">
<tr><td>Layer (type)</td><td>Output Shape</td><td>Param</td></tr>
<tr><td>dense_1 (Dense)</td><td>(None, 8)</td><td>16</td></tr>
<tr><td>leaky_re_lu_1 (LeakyReLU)</td><td>(None, 8)</td><td>0</td></tr>
<tr><td>dropout_1 (Dropout)</td><td>(None, 8)</td><td>0</td></tr>
<tr><td>dense_2 (Dense)</td><td>(None, 1)</td><td>9</td></tr>
</table>


Step 3: Train model
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r}
model <- keras_model_sequential()
model %>%
  layer_dense(units = 8, input_shape = 1) %>% # hidden layer with 8 neurons, 1-dimensional input
  layer_activation_leaky_relu() %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 1) # output layer with linear activation

# model %>% summary() # params: num_hidden weights and biases each to hidden layer, num_hidden weights and 1 bias to output neuron

model %>% compile(optimizer = "adam", loss = "mean_squared_error")
```


```{r, echo=TRUE, results="hide", fig.width=8, fig.height=4}
hist <-
  model %>% fit(
    x_train,
    y_train,
    batch_size = 10,
    epochs = 100
  )
model %>% save_model_hdf5("iris.h5")

plot(hist)
```


Step 4: Test model
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, echo=TRUE}
model <- load_model_hdf5("iris.h5")
model %>% evaluate(x_test, y_test)

preds_train <- model %>% predict(x_train)
preds_test <- model %>% predict(x_test)
```


```{r}
preds_df <-
  data.frame(predictor = x_train,
             actual = y_train,
             predicted = preds_train)
preds_df <- preds_df %>% gather(type, value,-predictor)
g1 <- ggplot(preds_df, aes(x = predictor, y = value)) + geom_point(aes(color = type)) +
   ggtitle("Predictions on training set") + 
  theme(title = bold_text_20, axis.title = bold_text_20, axis.text = bold_text_20)


preds_df <-
  data.frame(predictor = x_test,
             actual = y_test,
             predicted = preds_test)
preds_df <- preds_df %>% gather(type, value,-predictor)
g2 <- ggplot(preds_df, aes(x = predictor, y = value)) + geom_point(aes(color = type)) + 
   ggtitle("Predictions on test set") + 
  theme(title = bold_text_20, axis.title = bold_text_20, axis.text = bold_text_20)
grid.arrange(g1, g2, ncol=2)
```



========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>
Convolutional Neural Networks (CNNs)
</h1>


Going spatial: convnets
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

LeNet: First successful application of convolutional neural networks by Yann LeCun, Yoshua Bengio et al.

<figure>
    <img src='lenet.png' width='80%'/>
    <figcaption>Source: http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf</figcaption>
</figure>



The convolution operation
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

<figure>
    <img src='2dconv.png' width='40%'/>
    <figcaption>Source: Goodfellow et al., Deep Learning.</figcaption>
</figure>


CIFAR-10
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

32*32 px RGB images, split into training set (50000) and test set (10000)

```{r, echo=TRUE}
cifar10 <- dataset_cifar10()

x_train <- cifar10$train$x/255
x_test <- cifar10$test$x/255
y_train <- to_categorical(cifar10$train$y, num_classes = 10)
y_test <- to_categorical(cifar10$test$y, num_classes = 10)
```

```{r}
layout(matrix(1:20, 4, 5))

for (i in 1:20) {
  img <- transpose(Image(data = x_train[i, , , ], colormode = "Color"))
  display(img, method="raster", all = TRUE)
}
```

A (rather) simple convnet
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, echo=TRUE}
model <- keras_model_sequential()

model %>%
  layer_conv_2d(filters = 32, kernel_size = c(3,3), padding = "same", input_shape = c(32, 32, 3)) %>%
  layer_activation("relu") %>%
  
  layer_conv_2d(filters = 32, kernel_size = c(3,3)) %>% layer_activation("relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>% 
  layer_dropout(0.25) %>%
  
  layer_conv_2d(filters = 32, kernel_size = c(3,3), padding = "same") %>%
  layer_activation("relu") %>%
  
  layer_conv_2d(filter = 32, kernel_size = c(3,3)) %>%
  layer_activation("relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_dropout(0.25) %>%
  
  layer_flatten() %>%
  layer_dense(512) %>%
  layer_activation("relu") %>%
  layer_dropout(0.5) %>%

  layer_dense(10) %>%
  layer_activation("softmax")
```


Compile and train (not now)
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, echo=TRUE, eval=FALSE}
model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(lr = 0.0001, decay = 1e-6),
  metrics = "accuracy"
)
  
model %>% fit(
  x_train,
  y_train,
  batch_size = 32,
  epochs = 200,
  validation_data = list(x_test, y_test),
  shuffle = TRUE
)
```


Evaluate model
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, echo=TRUE}
model <- load_model_hdf5("cifar_10_200epochs.h5")
(model %>% evaluate(x_test, y_test))[[2]] # accuracy

y_test[1] # example image: true class
model %>% predict_proba(x_test[1, , , , drop = FALSE])
model %>% predict_classes(x_test[1, , , , drop = FALSE])
```


Why start from scratch? Pretrained models
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;


Available in Keras, with weights trained on ImageNet

- Inception V3
- VGG19, VGG19
- ResNet
- Xception

Usage:

- as is
- remove top fully connected layer and train for own classes
- remove top fully connected layer and train for own classes, fine-tune upper layers 
- extract features (top or intermediate)


What's this?
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

<figure>
    <img src='xc.jpg' width='30%'/>
    <figcaption>Source: Imagenet</figcaption>
</figure>


Ask VGG16
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, echo=TRUE}
model <- application_vgg16(weights = 'imagenet')

img_path <- "xc.jpg"
img <- image_load(img_path, target_size = c(224,224)) 
x <- image_to_array(img)
dim(x) <- c(1, dim(x))

x <- imagenet_preprocess_input(x)

preds <- model %>% predict(x)
imagenet_decode_predictions(preds)
```


Ask Resnet
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, echo=TRUE}
model <- application_resnet50(weights = 'imagenet')

img_path <- "xc.jpg"
img <- image_load(img_path, target_size = c(224,224)) 
x <- image_to_array(img)
dim(x) <- c(1, dim(x))

x <- imagenet_preprocess_input(x)

preds <- model %>% predict(x)
imagenet_decode_predictions(preds)
```


Ask Inception V3
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, echo=TRUE}
model <- application_inception_v3(weights = 'imagenet')

img_path <- "xc.jpg"
img <- image_load(img_path, target_size = c(299,299)) 
x <- image_to_array(img)
dim(x) <- c(1, dim(x))

x <- inception_v3_preprocess_input(x)

preds <- model %>% predict(x)
which.max(preds)
imagenet_decode_predictions(preds)
```



========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>
Long Short Term Memory (LSTM)
</h1>



Going sequential: Recurrent Neural Networks (RNNs)
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

<figure>
    <img src='rnn1.png' width='80%'/>
    <figcaption>Source: Goodfellow et al. 2016, Deep Learning</figcaption>
</figure>


I need to forget: Long Short Term Memory
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

<figure>
    <img src='lstm.png' align='left' width='60%'/> <img src='lstm2.png' align='right' width='40%'/>
    <figcaption>Source: <a href='http://cs224d.stanford.edu/lecture_notes/LectureNotes4.pdf'>Stanford CS 224D Deep Learning for NLP Lecture Notes</a></figcaption>
</figure>



Let's write ourselves some R (source!)
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

... character by character (fun read: <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks</a>)


Input: subset of .c files under $R_HOME/src/main

Like this, for example...

```
#ifdef HAVE_CONFIG_H
#include <config.h>
#endif

#include <Defn.h>
#include <Internal.h>

/* JMC convinced MM that this was not a good idea: */
#undef _S4_subsettable

static R_INLINE SEXP VECTOR_ELT_FIX_NAMED(SEXP y, R_xlen_t i) {
    /* if RHS (container or element) has NAMED > 0 set NAMED = 2.
       Duplicating might be safer/more consistent (fix bug reported by
       Radford Neal; similar to PR15098) */
    SEXP val = VECTOR_ELT(y, i);
    if ((NAMED(y) || NAMED(val)))
        if (NAMED(val) < 2)
            SET_NAMED(val, 2);
    return val;
}

```

Preprocessing for char-rnn
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;


Preprocessing steps:

- split into characters
- build a dictionary of characters
- build a list of (overlapping) character sequences of a specific length

```{r, eval = FALSE}
dataset <- map(
  seq(1, length(text) - maxlen - 1, by = 3), 
  function(x) list(sentence = text[x:(x + maxlen - 1)], next_char = text[x + maxlen])
)
```

Create X and y matrices in formats required by LSTM
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, eval=FALSE}
dataset <- transpose(dataset)

X <- array(0, dim = c(length(dataset$sentence), maxlen, length(chars)))
y <- array(0, dim = c(length(dataset$sentence), length(chars)))
dim(X)
dim(y)

for(i in 1:length(dataset$sentence)){  
  X[i,,] <- sapply(chars, function(x){
    as.integer(x == dataset$sentence[[i]])
  })  
  y[i,] <- as.integer(chars == dataset$next_char[[i]])
}

```

Define the model
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, eval = FALSE}
model <- keras_model_sequential()

model %>%
  layer_lstm(128, input_shape = c(maxlen, length(chars))) %>%
  layer_dense(length(chars)) %>%
  layer_activation("softmax")

optimizer <- optimizer_rmsprop(lr = 0.01)

model %>% compile(
  loss = "categorical_crossentropy", 
  optimizer = optimizer
)
```


60 epochs later... let's see some output!
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

