<style>

.reveal section img {
  border: 0px;
  box-shadow: 0 0 0 0;
}
.reveal table td {
  padding: 2px;
}

.reveal table {
  
}

.reveal h1 {
  font-size: 2em;
}

.reveal h3 {
  font-size: 1.2em;
}

.reveal figcaption {
  font-size: 0.4em;
}

.smallcode pre code {
  font-size: 0.9em;
}

.reveal .smalltext {
  font-size: 0.75em;
}

.reveal .mediumtext {
  font-size: 0.85em;
}

</style>


Deep learning with Keras - using R
========================================================
author: Sigrid Keydana, Trivadis
date: 2017/09/11
autosize: true
incremental:false
width: 1600
height: 900


About me & my employer
========================================================
class:mediumtext


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

Trivadis
- DACH-based IT consulting and service company, from traditional technologies to big data/machine learning/data science

My background
- from psychology/statistics via software development and database engineering to data science and ML/DL

My passion
- machine learning and deep learning
- data science and (Bayesian) statistics
- explanation/understanding over prediction accuracy

Where to find me
- blog: http://recurrentnull.wordpress.com
- twitter: @zkajdan




Welcome to the world of deep neural networks
========================================================

&nbsp;

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


&nbsp;

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=16, fig.height=8, fig.path='Figs/',
                      echo=FALSE, warning=FALSE, message=FALSE,
                      cache = TRUE)
```

```{r}
library(ggplot2)
library(dplyr)
library(forecast)
library(tidyr)
library(reticulate)
library(keras)
library(gridExtra)
library(EBImage)
library(readr)
library(stringr)
library(purrr)
library(tokenizers)

bold_text_20 <- element_text(face = "bold", size = 20)
bold_text_16 <- element_text(face = "bold", size = 16)
```

<figure>
    <img src='deep_nn.png' width='60%'/>
    <figcaption>Source: https://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol4/cs11/report.html</figcaption>
</figure>




How can we do deep learning in practice?
========================================================
incremental:true

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

Powerful frameworks:

- TensorFlow (Python)
- PyTorch (Python)
- Keras (Python)
- DL4J (Java)
- ...

But we want to use R!

&nbsp;

Let's just use Keras
========================================================
incremental:true


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

... from R!

How? 

With the <a href="https://keras.rstudio.com/"> R Interface to Keras, developed by RStudio</a>



Getting started with Keras
========================================================


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

Four steps:

0. prepare data
1. define model
2. train model
3. test model





Let's see how this works on our most beloved algorithm...
========================================================
incremental:true


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

... linear regression!

... using our most beloved dataset ...


========================================================
incremental:true


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


<figure>
    <img src='iris.jpg' width='60%'/>
</figure>



========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>
Linear regression with Keras
</h1>


The task
========================================================
class:smallcode

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


&nbsp;

We want to predict Petal.Width from Petal.Length ...

```{r, fig.width=8, fig.height = 4}
lm(Petal.Width ~ Petal.Length, data = iris) %>% summary()
ggplot(iris, aes(x = Petal.Length, y = Petal.Width, color = Species)) + geom_point() + geom_smooth()
```


Step 1: Prepare data
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

Not much to do in this case, just split into x/y and test & training sets:

```{r, echo=TRUE}
x_train <- iris[1:120, "Petal.Length"]
y_train <- iris[1:120, "Petal.Width"]
x_test <- iris[121:150, "Petal.Length"]
y_test <- iris[121:150, "Petal.Width"]
```


Step 2: Define model
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, echo=TRUE}
model <- keras_model_sequential()
model %>%
  layer_dense(units = 8, input_shape = 1) %>% # hidden layer with 8 neurons, 1-dimensional input
  layer_activation_leaky_relu() %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 1) # output layer with linear activation

# model %>% summary() # params: num_hidden weights and biases each to hidden layer, 8 weights and 1 bias to output neuron

model %>% compile(optimizer = "adam", loss = "mean_squared_error")
```

&nbsp;

<table style="margin-left: 200px;">
<tr><td>Layer (type)</td><td>Output Shape</td><td>Param</td></tr>
<tr><td>dense_1 (Dense)</td><td>(None, 8)</td><td>16</td></tr>
<tr><td>leaky_re_lu_1 (LeakyReLU)</td><td>(None, 8)</td><td>0</td></tr>
<tr><td>dropout_1 (Dropout)</td><td>(None, 8)</td><td>0</td></tr>
<tr><td>dense_2 (Dense)</td><td>(None, 1)</td><td>9</td></tr>
</table>


Step 3: Train model
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r}
model <- keras_model_sequential()
model %>%
  layer_dense(units = 8, input_shape = 1) %>% # hidden layer with 8 neurons, 1-dimensional input
  layer_activation_leaky_relu() %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 1) # output layer with linear activation

# model %>% summary() # params: num_hidden weights and biases each to hidden layer, num_hidden weights and 1 bias to output neuron

model %>% compile(optimizer = "adam", loss = "mean_squared_error")
```


```{r, echo=TRUE, results="hide", fig.width=8, fig.height=4}
hist <-
  model %>% fit(
    x_train,
    y_train,
    batch_size = 10,
    epochs = 100
  )
model %>% save_model_hdf5("iris.h5")

plot(hist)
```


Step 4: Test model
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, echo=TRUE}
model <- load_model_hdf5("iris.h5")
model %>% evaluate(x_test, y_test)

preds_train <- model %>% predict(x_train)
preds_test <- model %>% predict(x_test)
```


```{r}
preds_df <-
  data.frame(predictor = x_train,
             actual = y_train,
             predicted = preds_train)
preds_df <- preds_df %>% gather(type, value,-predictor)
g1 <- ggplot(preds_df, aes(x = predictor, y = value)) + geom_point(aes(color = type)) +
   ggtitle("Predictions on training set") + 
  theme(title = bold_text_20, axis.title = bold_text_20, axis.text = bold_text_20)


preds_df <-
  data.frame(predictor = x_test,
             actual = y_test,
             predicted = preds_test)
preds_df <- preds_df %>% gather(type, value,-predictor)
g2 <- ggplot(preds_df, aes(x = predictor, y = value)) + geom_point(aes(color = type)) + 
   ggtitle("Predictions on test set") + 
  theme(title = bold_text_20, axis.title = bold_text_20, axis.text = bold_text_20)
grid.arrange(g1, g2, ncol=2)
```



========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>
Convolutional Neural Networks (CNNs)
</h1>


Going spatial: convnets
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

LeNet: First successful application of convolutional neural networks by Yann LeCun, Yoshua Bengio et al.

<figure>
    <img src='lenet.png' width='80%'/>
    <figcaption>Source: http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf</figcaption>
</figure>



The convolution operation
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

<figure>
    <img src='2dconv.png' width='40%'/>
    <figcaption>Source: Goodfellow et al., Deep Learning.</figcaption>
</figure>


CIFAR-10
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

32*32 px RGB images, split into training set (50000) and test set (10000)

```{r, echo=TRUE}
cifar10 <- dataset_cifar10()

x_train <- cifar10$train$x/255
x_test <- cifar10$test$x/255
y_train <- to_categorical(cifar10$train$y, num_classes = 10)
y_test <- to_categorical(cifar10$test$y, num_classes = 10)
```

```{r}
layout(matrix(1:20, 4, 5))

for (i in 1:20) {
  img <- EBImage::transpose(Image(data = x_train[i, , , ], colormode = "Color"))
  display(img, method="raster", all = TRUE)
}

```

A (rather) simple convnet
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, echo=TRUE}
model <- keras_model_sequential()

model %>%
  layer_conv_2d(filters = 32, kernel_size = c(3,3), padding = "same", input_shape = c(32, 32, 3)) %>%
  layer_activation("relu") %>%
  
  layer_conv_2d(filters = 32, kernel_size = c(3,3)) %>% layer_activation("relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>% 
  layer_dropout(0.25) %>%
  
  layer_conv_2d(filters = 32, kernel_size = c(3,3), padding = "same") %>%
  layer_activation("relu") %>%
  
  layer_conv_2d(filter = 32, kernel_size = c(3,3)) %>%
  layer_activation("relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_dropout(0.25) %>%
  
  layer_flatten() %>%
  layer_dense(512) %>%
  layer_activation("relu") %>%
  layer_dropout(0.5) %>%

  layer_dense(10) %>%
  layer_activation("softmax")
```


Compile and train (not now)
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, echo=TRUE, eval=FALSE}
model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(lr = 0.0001, decay = 1e-6),
  metrics = "accuracy"
)
  
model %>% fit(
  x_train,
  y_train,
  batch_size = 32,
  epochs = 200,
  validation_data = list(x_test, y_test),
  shuffle = TRUE
)
```


Evaluate model
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, echo=TRUE}
model <- load_model_hdf5("cifar_10_200epochs.h5")
(model %>% evaluate(x_test, y_test))[[2]] # accuracy

y_test[1] # example image: true class
model %>% predict_proba(x_test[1, , , , drop = FALSE])
model %>% predict_classes(x_test[1, , , , drop = FALSE])
```


Why start from scratch? Pretrained models
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;


Available in Keras, with weights trained on ImageNet

- Inception V3
- VGG19, VGG19
- ResNet
- Xception

Usage:

- as is
- remove top fully connected layer and train for own classes
- remove top fully connected layer and train for own classes, fine-tune upper layers 
- extract features (top or intermediate)


What's this?
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

<figure>
    <img src='xc.jpg' width='30%'/>
    <figcaption>Source: Imagenet</figcaption>
</figure>


Ask VGG16
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, echo=TRUE}
model <- application_vgg16(weights = 'imagenet')

img_path <- "xc.jpg"
img <- image_load(img_path, target_size = c(224,224)) 
x <- image_to_array(img)
dim(x) <- c(1, dim(x))

x <- imagenet_preprocess_input(x)

preds <- model %>% predict(x)
imagenet_decode_predictions(preds)
```


Ask Resnet
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, echo=TRUE}
model <- application_resnet50(weights = 'imagenet')

img_path <- "xc.jpg"
img <- image_load(img_path, target_size = c(224,224)) 
x <- image_to_array(img)
dim(x) <- c(1, dim(x))

x <- imagenet_preprocess_input(x)

preds <- model %>% predict(x)
imagenet_decode_predictions(preds)
```


Ask Inception V3
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, echo=TRUE}
model <- application_inception_v3(weights = 'imagenet')

img_path <- "xc.jpg"
img <- image_load(img_path, target_size = c(299,299)) 
x <- image_to_array(img)
dim(x) <- c(1, dim(x))

x <- inception_v3_preprocess_input(x)

preds <- model %>% predict(x)
which.max(preds)
imagenet_decode_predictions(preds)
```



========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>
Long Short Term Memory (LSTM)
</h1>



Going sequential: Recurrent Neural Networks (RNNs)
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

<figure>
    <img src='rnn1.png' width='80%'/>
    <figcaption>Source: Goodfellow et al. 2016, Deep Learning</figcaption>
</figure>


I need to forget: Long Short Term Memory
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

<figure>
    <img src='lstm.png' align='left' width='60%'/> <img src='lstm2.png' align='right' width='40%'/>
    <figcaption>Source: <a href='http://cs224d.stanford.edu/lecture_notes/LectureNotes4.pdf'>Stanford CS 224D Deep Learning for NLP Lecture Notes</a></figcaption>
</figure>



Let's write ourselves some R (source!)
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

... character by character (fun read: <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks</a>)


Input: subset of .c files under $R_HOME/src/main

Like this, for example...

```
#ifdef HAVE_CONFIG_H
#include <config.h>
#endif

#include <Defn.h>
#include <Internal.h>

/* JMC convinced MM that this was not a good idea: */
#undef _S4_subsettable

static R_INLINE SEXP VECTOR_ELT_FIX_NAMED(SEXP y, R_xlen_t i) {
    /* if RHS (container or element) has NAMED > 0 set NAMED = 2.
       Duplicating might be safer/more consistent (fix bug reported by
       Radford Neal; similar to PR15098) */
    SEXP val = VECTOR_ELT(y, i);
    if ((NAMED(y) || NAMED(val)))
        if (NAMED(val) < 2)
            SET_NAMED(val, 2);
    return val;
}

```

Preprocessing for char-rnn
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;


Preprocessing steps:

- split into characters
- build a dictionary of characters
- build a list of (overlapping) character sequences of a specific length, and the corresponding following char

```{r, eval = FALSE, echo=TRUE}
dataset <- map(
  seq(1, length(text) - maxlen - 1, by = 3), 
  function(x) list(sentence = text[x:(x + maxlen - 1)], next_char = text[x + maxlen])
)
dataset[[14]]

```

```
$sentence
 [1] "s"  "t"  "i"  "c"  "a"  "l"  " "  "d"  "a"  "t"  "a"  " "  "a" 
[14] "n"  "a"  "l"  "y"  "s"  "i"  "s"  "\n" " "  "*"  " "  " "  "c" 
[27] "o"  "p"  "y"  "r"  "i"  "g"  "h"  "t"  " "  "("  "c"  ")"  " " 
[40] "1" 

$next_char
[1] "9"
``` 

Create X and y matrices in formats required by LSTM
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

LSTM needs as input a 3-dimensional array, where the sizes are, in order

- batch input size
- number of timesteps (characters to use for prediction, in our case)
- number of features (the dictionary of characters, in our case)

&nbsp;

```{r, eval=FALSE, echo=TRUE}
dataset <- transpose(dataset)

X <- array(0, dim = c(length(dataset$sentence), maxlen, length(chars)))
y <- array(0, dim = c(length(dataset$sentence), length(chars)))

for(i in 1:length(dataset$sentence)){  
  X[i,,] <- sapply(chars, function(x){
    as.integer(x == dataset$sentence[[i]])
  })  
  y[i,] <- as.integer(chars == dataset$next_char[[i]])
}

```



Define model
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r, eval = FALSE, echo=TRUE}
model <- keras_model_sequential()

model %>%
  layer_lstm(128, input_shape = c(maxlen, length(chars))) %>%
  layer_dense(length(chars)) %>%
  layer_activation("softmax")

optimizer <- optimizer_rmsprop(lr = 0.01)

model %>% compile(
  loss = "categorical_crossentropy", 
  optimizer = optimizer
)
```


60 epochs later... let's see some output!
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r}
maxlen <- 40
path <- "all.c"

sample_mod <- function(preds, temperature = 1){
  preds <- log(preds)/temperature
  exp_preds <- exp(preds)
  preds <- exp_preds/sum(exp(preds))
  
  rmultinom(1, 1, preds) %>% 
    as.integer() %>%
    which.max()
}

model <- load_model_hdf5("char_rnn_60.h5")

text <- read_lines(path) %>%
  str_to_lower() %>%
  str_c(collapse = "\n") %>%
  tokenize_characters(strip_non_alphanum = FALSE, simplify = TRUE)

chars <- text %>%
  unique() %>%
  sort()


start_index <- sample(1:(length(text) - maxlen), size = 1)
sentence <- text[start_index:(start_index + maxlen - 1)]
generated <- ""
      
for(i in 1:400){
        
  x <- sapply(chars, function(x){
       as.integer(x == sentence)
  })
  x <- array_reshape(x, c(1, dim(x)))
        
  preds <- predict(model, x)
  next_index <- sample_mod(preds, temperature = 0.2)
  next_char <- chars[next_index]
        
  generated <- str_c(generated, next_char, collapse = "")
  sentence <- c(sentence[-1], next_char)
}
cat(generated)
```

&nbsp;

Could be C to me ;-)

Another one... more adventurous this time...
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r}
model <- load_model_hdf5("char_rnn_60.h5")

start_index <- sample(1:(length(text) - maxlen), size = 1)
sentence <- text[start_index:(start_index + maxlen - 1)]
generated <- ""
      
for(i in 1:400){
        
  x <- sapply(chars, function(x){
       as.integer(x == sentence)
  })
  x <- array_reshape(x, c(1, dim(x)))
        
  preds <- predict(model, x)
  next_index <- sample_mod(preds, temperature = 1)
  next_char <- chars[next_index]
        
  generated <- str_c(generated, next_char, collapse = "")
  sentence <- c(sentence[-1], next_char)
}
cat(generated)
```


... and a still more creative one...
========================================================
class:mediumtext

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r}
model <- load_model_hdf5("char_rnn_60.h5")

start_index <- sample(1:(length(text) - maxlen), size = 1)
sentence <- text[start_index:(start_index + maxlen - 1)]
generated <- ""
      
for(i in 1:400){
        
  x <- sapply(chars, function(x){
       as.integer(x == sentence)
  })
  x <- array_reshape(x, c(1, dim(x)))
        
  preds <- predict(model, x)
  next_index <- sample_mod(preds, temperature = 1.6)
  next_char <- chars[next_index]
        
  generated <- str_c(generated, next_char, collapse = "")
  sentence <- c(sentence[-1], next_char)
}
cat(generated)
```

&nbsp;

Now we know where the "less helpful error messages" come from ;-)



Another cool thing we can do with LSTMs: Time series forecasting
========================================================
class:smallcode

&nbsp;

Take this one:

```{r}
traffic_df <- read_csv("internet-traffic-data-in-bits-fr.csv", col_names = c("hour", "bits"), skip = 1)
ggplot(traffic_df, aes(x = hour, y = bits)) + geom_line() + ggtitle("Internet traffic  in bits, 7 June to 31 July 2005. Hourly data.") + theme(title = bold_text_16, axis.title = bold_text_16, axis.text = bold_text_16)


```

This series has _multiple seasonality_.

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />





One-step-ahead forecasts
========================================================
class:smallcode

&nbsp;

Preprocessing:

- Scale/normalize the data (especially with extremely high values like this!)
- Again, reshape data to the form <_num samples, num timesteps, num features_>

Model definition:

```{r, echo=TRUE, eval=FALSE}
model %>% 
  layer_lstm(units = lstm_units, input_shape = c(num_steps, num_features)) %>% 
  layer_dense(units = 1) %>% 
  compile(
    loss = 'mean_squared_error',
    optimizer = 'adam'
  )
```


&nbsp;

Where the number of timesteps is chosen to be 24 hours * 7 days = 168.

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />



And after about 20 epochs of training...
========================================================
class:smallcode

&nbsp;

... here are the forecasts:

```{r, results="hide"}
source("functions.R")
traffic_df <- read_csv("internet-traffic-data-in-bits-fr.csv", col_names = c("hour", "bits"), skip = 1)

internet_train <- traffic_df$bits[1:800]
internet_test <- traffic_df$bits[801:nrow(traffic_df)]

model_exists <- TRUE

lstm_num_timesteps <- 7*24
batch_size <- 1
epochs <- 500
lstm_units <- 32
model_type <- "model_lstm_simple"
lstm_type <- "stateless"
data_type <- "data_scaled"
test_type <- "INTERNET"

model_name <- "model_lstm_simple_stateless_data_scaled_INTERNET_500_epochs"

cat("\n####################################################################################")
cat("\nRunning model: ", model_name)
cat("\n####################################################################################")

train <- internet_train[!is.na(internet_train)]
test <- internet_test[!is.na(internet_test)]

# normalize
minval <- min(train)
maxval <- max(train)

train <- normalize(train, minval, maxval)
test <- normalize(test, minval, maxval)

X_train <- build_X(train, lstm_num_timesteps) 
y_train <- build_y(train, lstm_num_timesteps) 

X_test <- build_X(test, lstm_num_timesteps) 
y_test <- build_y(test, lstm_num_timesteps) 

# Keras LSTMs expect the input array to be shaped as (no. samples, no. time steps, no. features)
X_train <- reshape_X_3d(X_train)
X_test <- reshape_X_3d(X_test)

num_samples <- dim(X_train)[1]
num_steps <- dim(X_train)[2]
num_features <- dim(X_train)[3]

# model
if (!model_exists) {
  set.seed(22222)
  model <- keras_model_sequential() 
  model %>% 
    layer_lstm(units = lstm_units, input_shape = c(num_steps, num_features)) %>% 
    layer_dense(units = 1) %>% 
    compile(
      loss = 'mean_squared_error',
      optimizer = 'adam'
    )
  
  model %>% summary()
  
  model %>% fit( 
    X_train, y_train, batch_size = batch_size, epochs = epochs,
    validation_data = list(X_test, y_test),
    callbacks = callback_early_stopping(patience=2)
    
  )
  model %>% save_model_hdf5(filepath = paste0(model_name, ".h5"))
} else {
  model <- load_model_hdf5(filepath = paste0(model_name, ".h5"))
}

pred_train <- model %>% predict(X_train, batch_size = 1)
pred_test <- model %>% predict(X_test, batch_size = 1)

pred_train <- denormalize(pred_train, minval, maxval)
pred_test <- denormalize(pred_test, minval, maxval)

df <- data_frame(
                 time_id = 1:1231,
                 train = c(internet_train, rep(NA, length(internet_test))),
                 test = c(rep(NA, length(internet_train)), internet_test),
                 pred_train_ = c(rep(NA, lstm_num_timesteps), pred_train, rep(NA, length(internet_test))),
                 pred_test_ = c(rep(NA, length(internet_train)), rep(NA, lstm_num_timesteps), pred_test)
   )
df <- df %>% gather(key = 'type', value = 'value', train:pred_test_)
ggplot(df, aes(x = time_id, y = value)) + geom_line(aes(color = type))
```



<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


How about multi-step-ahead forecasts?
========================================================
class:smallcode

&nbsp;

We can use Keras TimeDistributed layer for this.

```{r, eval=FALSE, echo = TRUE}
lstm_units <- 24 * 7 # hourly * weekly
model %>% 
  layer_lstm(units = lstm_units, input_shape = c(num_steps, num_features),
               return_sequences = TRUE) %>% 
  time_distributed(layer_dense(units = 1)) %>% 
  compile(
    loss = 'mean_squared_error',
    optimizer = 'adam'
)
```

&nbsp;

Where number of predictions equals number of timesteps: 168.

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />




168-step-ahead forecasts!
========================================================
class:smallcode

&nbsp;

And here are the forecasts, 168 steps ahead (displaying 3 only)

&nbsp;

```{r, results="hide"}
internet_train <- traffic_df$bits[1:800]
internet_test <- traffic_df$bits[801:nrow(traffic_df)]

model_exists <- TRUE

lstm_num_predictions <- 168
lstm_num_timesteps <- 168
batch_size <- 1
epochs <- 500
lstm_units <- 32
lstm_type <- "stateless"
data_type <- "data_scaled"
test_type <- "INTERNET"
model_type <- "model_lstm_time_distributed"

model_name <- "model_lstm_time_distributed_stateless_data_scaled_internet_timesteps_168"

train <- internet_train[!is.na(internet_train)]
test <- internet_test[!is.na(internet_test)]

num_train <- length(train)
num_test <- length(test)
num_all <- num_train + num_test

# normalize
minval <- min(train)
maxval <- max(train)

train <- normalize(train, minval, maxval)
test <- normalize(test, minval, maxval)

matrix_train <- build_matrix(train, lstm_num_timesteps + lstm_num_predictions) 
matrix_test <- build_matrix(test, lstm_num_timesteps + lstm_num_predictions) 

X_train <- matrix_train[ ,1:lstm_num_timesteps]
y_train <- matrix_train[ ,(lstm_num_timesteps + 1):(lstm_num_timesteps + lstm_num_predictions)]

X_test <- matrix_test[ ,1:lstm_num_timesteps]
y_test <- matrix_test[ ,(lstm_num_timesteps + 1):(lstm_num_timesteps + lstm_num_predictions)]

# Keras LSTMs expect the input array to be shaped as (no. samples, no. time steps, no. features)
X_train <- reshape_X_3d(X_train)
X_test <- reshape_X_3d(X_test)

y_train <- reshape_X_3d(y_train)
y_test <- reshape_X_3d(y_test)

num_samples <- dim(X_train)[1]
num_steps <- dim(X_train)[2]
num_features <- dim(X_train)[3]

# model
if (!model_exists) {
  set.seed(22222)
  model <- keras_model_sequential() 
  model %>% 
    layer_lstm(units = lstm_units, input_shape = c(num_steps, num_features),
               return_sequences = TRUE) %>% 
    time_distributed(layer_dense(units = 1)) %>% 
    compile(
      loss = 'mean_squared_error',
      optimizer = 'adam'
    )
  
  model %>% summary()
  
  model %>% fit( 
    X_train, y_train, batch_size = batch_size, epochs = epochs,
    validation_data = list(X_test, y_test), callbacks = callback_early_stopping(patience=2)
  )
  model %>% save_model_hdf5(filepath = paste0(model_name, ".h5"))
} else {
  model <- load_model_hdf5(filepath = paste0(model_name, ".h5"))
}

pred_train <- model %>% predict(X_train, batch_size = 1)
pred_test <- model %>% predict(X_test, batch_size = 1)

pred_train <- denormalize(pred_train, minval, maxval)
pred_test <- denormalize(pred_test, minval, maxval)

pred_train <- pred_train[ , , 1]
pred_test <- pred_test[ , , 1]

df <- data_frame(time_id = 1:length(test),
                 test = denormalize(test, minval, maxval))
for(i in seq_len(nrow(pred_test))) {
  varname <- paste0("pred_test", i)
  df <- mutate(df, !!varname := c(rep(NA, lstm_num_timesteps),
                                  rep(NA, i-1),
                                  pred_test[i, ],
                                  rep(NA, num_test - lstm_num_predictions - lstm_num_timesteps -i +1)))
}

ggplot(df, aes(x = time_id, y =test)) + geom_line()  +
 geom_line(aes(y = pred_test1), color = "cyan") + 
  geom_line(aes(y = pred_test48), color = "red") + 
  geom_line(aes(y = pred_test96), color = "green")  + 
  ggtitle("Internet traffic  in bits. 168-step-ahead forecasts for the test set.") + theme(title = bold_text_16, axis.title = bold_text_16, axis.text = bold_text_16)
  
```


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


That's just a small glimpse of what you could do...
========================================================
class:smallcode

&nbsp;

... with Keras, in R.

Go ahead and have fun :-)

&nbsp;

Thanks for your attention!!

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />




